{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPlHqw1ZaEqBrmBUTbkMIPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strumberr/fine-tuned-carlsen-model/blob/main/Current_Best_Chess_Magnus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "59L12kTn_fE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c49d57-ed78-4253-a792-393754b2ce7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: python-chess in /usr/local/lib/python3.11/dist-packages (1.999)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: chess<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-chess) (1.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers python-chess torch numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "import chess.pgn\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, AutoTokenizer, Trainer, TrainingArguments, GPT2Model, AutoModel\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# # Authenticate with Hugging Face\n",
        "# hf_token = userdata.get('HF_TOKEN')\n",
        "# if hf_token:\n",
        "#     login(token=hf_token)\n",
        "# else:\n",
        "#     raise ValueError(\"HF_TOKEN not found in Colab secrets. Please add it at https://huggingface.co/settings/tokens.\")\n"
      ],
      "metadata": {
        "id": "SGSez48Y_n2B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_magnus_pgn(pgn_file_path):\n",
        "    positions = []\n",
        "    with open(pgn_file_path, 'r', encoding='utf-8') as pgn_file:\n",
        "        while True:\n",
        "            game = chess.pgn.read_game(pgn_file)\n",
        "            if game is None:\n",
        "                break\n",
        "            magnus_color = \"white\" if \"Carlsen\" in game.headers.get(\"White\", \"\") else \"black\"\n",
        "            if \"Carlsen\" not in game.headers.get(\"White\", \"\") and \"Carlsen\" not in game.headers.get(\"Black\", \"\"):\n",
        "                continue\n",
        "            if \"blitz\" in game.headers.get(\"Event\", \"\").lower() or \"bullet\" in game.headers.get(\"Event\", \"\").lower():\n",
        "                continue\n",
        "            board = game.board()\n",
        "            node = game\n",
        "            while node.variations:\n",
        "                next_node = node.variation(0)\n",
        "                if (board.turn == chess.WHITE and magnus_color == \"white\") or \\\n",
        "                   (board.turn == chess.BLACK and magnus_color == \"black\"):\n",
        "                    positions.append((board.fen(), next_node.move.uci()))\n",
        "                board.push(next_node.move)\n",
        "                node = next_node\n",
        "    return positions\n",
        "\n",
        "\n",
        "def tokenize_fen(fen, tokenizer):\n",
        "    tokens = tokenizer(fen, padding=\"max_length\", max_length=64, truncation=True, return_tensors=\"pt\")\n",
        "    return tokens\n",
        "\n",
        "def encode_move(move_str):\n",
        "    move = chess.Move.from_uci(move_str)\n",
        "    return move.from_square * 64 + move.to_square\n",
        "\n",
        "\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, fens, moves, tokenizer):\n",
        "        self.fens = fens\n",
        "        self.moves = [encode_move(move) for move in moves]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.tokenized_data = [tokenize_fen(fen, tokenizer) for fen in fens]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenized_data[idx]\n",
        "        return {\n",
        "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.moves[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "class ChessMoveClassifier(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.base_model = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(self.base_model.config.hidden_size, 4096)  # 64x64\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None, labels=None):\n",
        "      outputs = self.base_model(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask,\n",
        "          token_type_ids=token_type_ids  # pass it to the base model anyway\n",
        "      )\n",
        "      hidden_state = outputs.last_hidden_state[:, 0, :]  # use [CLS] token\n",
        "      logits = self.classifier(hidden_state)\n",
        "\n",
        "      if labels is not None:\n",
        "          loss = F.cross_entropy(logits, labels)\n",
        "          return {\"loss\": loss, \"logits\": logits}\n",
        "      return {\"logits\": logits}\n"
      ],
      "metadata": {
        "id": "BB3RaWGr_zJe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    import os\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    model_name = \"austindavis/ChessGPT_d12\"\n",
        "\n",
        "    wandb.init(\n",
        "      project=\"magnus-chessgpt-finetune\",\n",
        "      name=\"chessgpt-finetune-run\",\n",
        "      config={\n",
        "        \"model_name\": model_name,\n",
        "        \"epochs\": 3,\n",
        "        \"train_batch_size\": 16,\n",
        "        \"eval_batch_size\": 32,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_steps\": 100,\n",
        "        \"max_seq_length\": 64,\n",
        "        \"tokenizer\": model_name,\n",
        "        \"dataset\": \"carlsen-train + carlsen-test\",\n",
        "        \"optimizer\": \"AdamW\",\n",
        "        \"architecture\": \"GPT2-base + linear classifier (4096)\",\n",
        "      }\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = ChessMoveClassifier(model_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_positions = parse_magnus_pgn(\"/content/carlsen-train.pgn\")\n",
        "    test_positions = parse_magnus_pgn(\"/content/carlsen-test.pgn\")\n",
        "    print(f\"Train positions: {len(train_positions)} | Test positions: {len(test_positions)}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"train_samples\": len(train_positions),\n",
        "        \"test_samples\": len(test_positions),\n",
        "    })\n",
        "\n",
        "    model.base_model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Split 10% validation from training\n",
        "    fens_all, moves_all = zip(*train_positions)\n",
        "    fens_train, fens_val, moves_train, moves_val = train_test_split(\n",
        "        fens_all, moves_all, test_size=0.1, random_state=42, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Subsample 5% of the training data\n",
        "    train_fraction = 0.05\n",
        "    num_train_samples = int(len(fens_train) * train_fraction)\n",
        "    fens_train = fens_train[:num_train_samples]\n",
        "    moves_train = moves_train[:num_train_samples]\n",
        "\n",
        "    wandb.log({\"train_fraction_used\": train_fraction, \"train_samples_used\": len(fens_train)})\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = ChessDataset(fens_train, moves_train, tokenizer)\n",
        "    val_dataset = ChessDataset(fens_val, moves_val, tokenizer)\n",
        "    test_fens, test_moves = zip(*test_positions)\n",
        "    test_dataset = ChessDataset(test_fens, test_moves, tokenizer)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=32,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        run_name=\"MagnusTransformer-finetune\",\n",
        "        report_to=\"wandb\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "\n",
        "    os.makedirs(\"/content/fine_tuned_chessgpt2\", exist_ok=True)\n",
        "    torch.save(model.state_dict(), \"/content/fine_tuned_chessgpt2/model.pt\")\n",
        "    tokenizer.save_pretrained(\"/content/fine_tuned_chessgpt2\")\n",
        "    print(\"Model saved to /content/fine_tuned_chessgpt2\")\n",
        "\n",
        "    print(\"Evaluating on test set...\")\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "\n",
        "    logits = predictions.predictions\n",
        "    true_labels = predictions.label_ids\n",
        "    predicted_indices = np.argmax(logits, axis=1)\n",
        "    correct = (predicted_indices == true_labels).sum()\n",
        "    total = len(true_labels)\n",
        "    accuracy = correct / total\n",
        "    wandb.log({\"test_accuracy\": accuracy})\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(true_labels, predicted_indices, labels=np.arange(4096))\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm[:10, :10], annot=True, fmt=\"d\", cmap=\"viridis\")  # partial view for sanity\n",
        "    plt.title(\"Confusion Matrix (first 10 classes)\")\n",
        "    wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n",
        "    plt.close()\n",
        "\n",
        "    def predict_magnus_move(fen):\n",
        "        model.eval()\n",
        "        inputs = tokenize_fen(fen, tokenizer)\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predicted_index = outputs[\"logits\"].argmax(dim=-1).item()\n",
        "        from_sq = predicted_index // 64\n",
        "        to_sq = predicted_index % 64\n",
        "        move = chess.Move(from_sq, to_sq)\n",
        "        board = chess.Board(fen)\n",
        "        if move in board.legal_moves:\n",
        "            return move.uci()\n",
        "        legal_moves = list(board.legal_moves)\n",
        "        return legal_moves[0].uci() if legal_moves else \"No legal move\"\n",
        "\n",
        "    fen = \"rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1\"\n",
        "    predicted_move = predict_magnus_move(fen)\n",
        "    print(f\"Magnus would play: {predicted_move}\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"sample_fen\": fen,\n",
        "        \"predicted_move\": predicted_move,\n",
        "    })\n",
        "\n",
        "    artifact = wandb.Artifact(\"fine-tuned-chessgpt\", type=\"model\")\n",
        "    artifact.add_dir(\"/content/fine_tuned_chessgpt2\")\n",
        "    wandb.log_artifact(artifact)\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "jwEvKxcM_3Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV0lMKEZRsvR",
        "outputId": "733fc315-09e1-4c64-d80e-5fa35a7e2895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-play"
      ],
      "metadata": {
        "id": "bmjmz61LlW0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.pgn\n",
        "import datetime\n",
        "import random\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoConfig, GPT2Model\n",
        "import torch.nn as nn\n",
        "\n",
        "# === Load model manually ===\n",
        "\n",
        "class ChessMoveClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=4096):\n",
        "        super().__init__()\n",
        "        self.base_model = GPT2Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.base_model.config.n_embd, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, **kwargs):  # <-- added **kwargs\n",
        "      outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      hidden_state = outputs.last_hidden_state[:, -1, :]  # Use last token\n",
        "      logits = self.classifier(self.dropout(hidden_state))\n",
        "      return {\"logits\": logits}\n",
        "\n",
        "\n",
        "model_dir = \"/content/fine_tuned_chessgpt2\"\n",
        "base_model = \"austindavis/ChessGPT_d12\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = ChessMoveClassifier(base_model)\n",
        "model.load_state_dict(torch.load(f\"{model_dir}/model.pt\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# === Tokenize FEN ===\n",
        "def tokenize_fen(fen, tokenizer):\n",
        "    return tokenizer(fen, return_tensors=\"pt\")\n",
        "\n",
        "# === Start game ===\n",
        "board = chess.Board()\n",
        "for _ in range(random.randint(4, 12)):\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    if not legal_moves:\n",
        "        break\n",
        "    board.push(random.choice(legal_moves))\n",
        "\n",
        "starting_fen = board.fen()\n",
        "print(f\"Starting self-play game from position:\\n{starting_fen}\\n\")\n",
        "\n",
        "# === PGN setup ===\n",
        "game = chess.pgn.Game()\n",
        "game.headers[\"Event\"] = \"ChessGPT Self-Play (Random Start)\"\n",
        "game.headers[\"Date\"] = datetime.datetime.now().strftime(\"%Y.%m.%d\")\n",
        "game.setup(board)\n",
        "node = game\n",
        "\n",
        "# === Self-play ===\n",
        "turn = 0\n",
        "max_turns = 100\n",
        "\n",
        "while turn < max_turns and not board.is_game_over():\n",
        "    inputs = tokenize_fen(board.fen(), tokenizer)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs)[\"logits\"]\n",
        "        sorted_indices = torch.argsort(logits, dim=-1, descending=True)[0]\n",
        "\n",
        "        for idx in sorted_indices:\n",
        "            from_sq = (idx // 64).item()\n",
        "            to_sq = (idx % 64).item()\n",
        "            move = chess.Move(from_sq, to_sq)\n",
        "            if move in board.legal_moves:\n",
        "                board.push(move)\n",
        "                node = node.add_variation(move)\n",
        "                print(f\"{'White' if turn % 2 == 0 else 'Black'} plays: {move.uci()}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"[!] No valid moves predicted\")\n",
        "            break\n",
        "\n",
        "    turn += 1\n",
        "\n",
        "# === Save game ===\n",
        "game.headers[\"Result\"] = board.result()\n",
        "with open(\"self_play_game_random.pgn\", \"w\") as f:\n",
        "    f.write(str(game))\n",
        "\n",
        "print(\"Game saved to self_play_game_random.pgn\")\n"
      ],
      "metadata": {
        "id": "EY2JV9YwBYK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base model VS magnus"
      ],
      "metadata": {
        "id": "UyGvgmyPnP2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "import chess.pgn\n",
        "import datetime\n",
        "import torch\n",
        "import random\n",
        "from transformers import AutoTokenizer, GPT2Model\n",
        "import torch.nn as nn\n",
        "\n",
        "# === Model class ===\n",
        "class ChessMoveClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=4096):\n",
        "        super().__init__()\n",
        "        self.base_model = GPT2Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.base_model.config.n_embd, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state[:, -1, :]\n",
        "        logits = self.classifier(self.dropout(hidden_state))\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "# === Setup device ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# === Load tokenizer ===\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"austindavis/ChessGPT_d12\")\n",
        "\n",
        "# === Load fine-tuned MagnusGPT ===\n",
        "magnus_model = ChessMoveClassifier(\"austindavis/ChessGPT_d12\")\n",
        "magnus_model.load_state_dict(torch.load(\"/content/fine_tuned_chessgpt2/model.pt\", map_location=device))\n",
        "magnus_model.to(device)\n",
        "magnus_model.eval()\n",
        "\n",
        "# === Load base model ===\n",
        "base_model = ChessMoveClassifier(\"austindavis/ChessGPT_d12\")\n",
        "base_model.to(device)\n",
        "base_model.eval()\n",
        "\n",
        "# === Tokenizer wrapper ===\n",
        "def tokenize_fen(fen):\n",
        "    return tokenizer(fen, return_tensors=\"pt\")\n",
        "\n",
        "# === Start from random legal position ===\n",
        "board = chess.Board()\n",
        "for _ in range(random.randint(4, 12)):\n",
        "    legal_moves = list(board.legal_moves)\n",
        "    if not legal_moves:\n",
        "        break\n",
        "    board.push(random.choice(legal_moves))\n",
        "\n",
        "starting_fen = board.fen()\n",
        "print(f\"Starting from position:\\n{starting_fen}\\n\")\n",
        "\n",
        "# === Setup PGN ===\n",
        "game = chess.pgn.Game()\n",
        "game.headers[\"Event\"] = \"MagnusGPT vs BaseGPT\"\n",
        "game.headers[\"Date\"] = datetime.datetime.now().strftime(\"%Y.%m.%d\")\n",
        "game.setup(board)\n",
        "node = game\n",
        "\n",
        "# === Self-play match ===\n",
        "turn = 0\n",
        "max_turns = 100\n",
        "\n",
        "while turn < max_turns and not board.is_game_over():\n",
        "    inputs = tokenize_fen(board.fen())\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # White = MagnusGPT, Black = BaseGPT\n",
        "    model = magnus_model if board.turn == chess.WHITE else base_model\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs)[\"logits\"]\n",
        "        sorted_indices = torch.argsort(logits, dim=-1, descending=True)[0]\n",
        "\n",
        "        for idx in sorted_indices:\n",
        "            from_sq = (idx // 64).item()\n",
        "            to_sq = (idx % 64).item()\n",
        "            move = chess.Move(from_sq, to_sq)\n",
        "            if move in board.legal_moves:\n",
        "                board.push(move)\n",
        "                node = node.add_variation(move)\n",
        "                print(f\"{'White (Magnus)' if board.turn == chess.BLACK else 'Black (Base)'} plays: {move.uci()}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"[!] No valid moves predicted\")\n",
        "            break\n",
        "\n",
        "    turn += 1\n",
        "\n",
        "# === Finalize game ===\n",
        "game.headers[\"Result\"] = board.result()\n",
        "with open(\"magnus_vs_base.pgn\", \"w\") as f:\n",
        "    f.write(str(game))\n",
        "\n",
        "print(\"Game saved to magnus_vs_base.pgn\")\n"
      ],
      "metadata": {
        "id": "0CzPbNN1AN-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Does the model play like magnus?"
      ],
      "metadata": {
        "id": "_dGp0E1rn-Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chess.pgn\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GPT2Model\n",
        "import torch.nn as nn\n",
        "import io\n",
        "\n",
        "# === Model class ===\n",
        "class ChessMoveClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=4096):\n",
        "        super().__init__()\n",
        "        self.base_model = GPT2Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.base_model.config.n_embd, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state[:, -1, :]\n",
        "        logits = self.classifier(self.dropout(hidden_state))\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "# === Tokenizer wrapper ===\n",
        "def tokenize_fen(fen, tokenizer):\n",
        "    return tokenizer(fen, return_tensors=\"pt\")\n",
        "\n",
        "# === Load model and tokenizer ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"austindavis/ChessGPT_d12\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/fine_tuned_chessgpt2\")\n",
        "model = ChessMoveClassifier(model_name)\n",
        "model.load_state_dict(torch.load(\"/content/fine_tuned_chessgpt2/model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# === PGN of real Magnus game (as Black) ===\n",
        "pgn_text = \"\"\"[Event \"5th OIBM\"]\n",
        "[Site \"Bad Wiessee GER\"]\n",
        "[Date \"2001.10.27\"]\n",
        "[Round \"1\"]\n",
        "[White \"Kacheishvili,G\"]\n",
        "[Black \"Carlsen,M\"]\n",
        "[Result \"1-0\"]\n",
        "[WhiteElo \"2583\"]\n",
        "[BlackElo \"2072\"]\n",
        "[ECO \"E32\"]\n",
        "\n",
        "1.d4 Nf6 2.c4 e6 3.Nc3 Bb4 4.Qc2 O-O 5.a3 Bxc3+ 6.Qxc3 b6 7.Bg5 Bb7 8.e3 c5\n",
        "9.dxc5 bxc5 10.Ne2 Nc6 11.Ng3 Qa5 12.Bxf6 gxf6 13.Qxa5 Nxa5 14.Nh5 Rfd8 15.O-O-O Kf8\n",
        "16.Nxf6 Ke7 17.Nh5 Ba6 18.Nf4 Bxc4 19.Bxc4 Nxc4 20.Rhe1 Rab8 21.Re2 d5 22.Rc2 Na5\n",
        "23.Kb1 c4 24.Ne2 Nb7 25.e4 Nc5 26.exd5 Rxd5 27.Nc3 Rg5 28.f4 Rh5 29.Rd4 Rxh2\n",
        "30.Rxc4 Nd3 31.Ka2 Rb7 32.Ne4 Rd7 33.Nc5 Nxc5 34.Rxc5 Kf6 35.Ra5 Rb7 36.f5 e5\n",
        "37.Re2 Re7 38.Ra6+ Kg5 39.f6 Rb7 40.Rxe5+ Kg6 41.Re7 Rb8 42.Raxa7 Rxg2 43.Rab7 Rxb7\n",
        "44.Rxb7 h5 45.a4 Rg4 46.Ka3 h4 47.Rb8 Rg3+ 48.b3 Kxf6 49.Rh8 Kg5 50.a5 Re3\n",
        "51.Ka4 Re6 52.b4 f5 53.b5 Re1 54.a6 Ra1+ 55.Kb4 f4 56.Kc5 f3 57.b6 Ra5+ 58.Kd4 Rxa6\n",
        "59.b7 Rb6 60.b8=Q Rxb8 61.Rxb8 Kf4 62.Rf8+ Kg3 63.Ke3 1-0\n",
        "\"\"\"\n",
        "\n",
        "# === Parse game ===\n",
        "game = chess.pgn.read_game(io.StringIO(pgn_text))\n",
        "board = game.board()\n",
        "magnus_moves = []\n",
        "fens = []\n",
        "\n",
        "# Magnus is Black, so collect FENs before each Black move\n",
        "for idx, move in enumerate(game.mainline_moves()):\n",
        "    if idx % 2 == 1:  # Black's turn\n",
        "        fens.append(board.fen())\n",
        "        magnus_moves.append(move.uci())\n",
        "    board.push(move)\n",
        "\n",
        "# === Run predictions and compare ===\n",
        "correct = 0\n",
        "total = len(fens)\n",
        "\n",
        "for i in range(total):\n",
        "    fen = fens[i]\n",
        "    true_move = magnus_moves[i]\n",
        "    inputs = tokenize_fen(fen, tokenizer)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs)[\"logits\"]\n",
        "        sorted_indices = torch.argsort(logits, dim=-1, descending=True)[0]\n",
        "\n",
        "        predicted_move = None\n",
        "        board = chess.Board(fen)\n",
        "        for idx in sorted_indices:\n",
        "            from_sq = (idx // 64).item()\n",
        "            to_sq = (idx % 64).item()\n",
        "            move = chess.Move(from_sq, to_sq)\n",
        "            if move in board.legal_moves:\n",
        "                predicted_move = move.uci()\n",
        "                break\n",
        "\n",
        "        is_correct = (predicted_move == true_move)\n",
        "        correct += int(is_correct)\n",
        "\n",
        "        print(f\"[{i+1}] True: {true_move} | Predicted: {predicted_move} | {'✅' if is_correct else '❌'}\")\n",
        "\n",
        "# === Accuracy report ===\n",
        "accuracy = correct / total\n",
        "print(f\"\\nMagnus Match Accuracy: {accuracy:.2%} ({correct}/{total})\")\n"
      ],
      "metadata": {
        "id": "RdFG_T8DoAz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy test training data with carlsons games and the model"
      ],
      "metadata": {
        "id": "Mpprw9vDoaNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chess.pgn\n",
        "import torch\n",
        "from transformers import AutoTokenizer, GPT2Model\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Model class ===\n",
        "class ChessMoveClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=4096):\n",
        "        super().__init__()\n",
        "        self.base_model = GPT2Model.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(self.base_model.config.n_embd, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, **kwargs):\n",
        "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state[:, -1, :]\n",
        "        logits = self.classifier(self.dropout(hidden_state))\n",
        "        return {\"logits\": logits}\n",
        "\n",
        "# === Tokenizer wrapper ===\n",
        "def tokenize_fen(fen, tokenizer):\n",
        "    return tokenizer(fen, return_tensors=\"pt\")\n",
        "\n",
        "# Load tokenizer and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"austindavis/ChessGPT_d12\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/fine_tuned_chessgpt2\")\n",
        "model = ChessMoveClassifier(model_name)\n",
        "model.load_state_dict(torch.load(\"/content/fine_tuned_chessgpt2/model.pt\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# First pass to count games\n",
        "with open(\"/content/carlsen-train.pgn\", \"r\", encoding=\"utf-8\") as f:\n",
        "    game_count = sum(1 for line in f if line.strip() == \"\")\n",
        "\n",
        "# Evaluation loop with live accuracy updates\n",
        "pgn_path = \"/content/carlsen-train.pgn\"\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with open(pgn_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    with tqdm(total=game_count, desc=\"Processing games\") as pbar:\n",
        "        while True:\n",
        "            game = chess.pgn.read_game(f)\n",
        "            if game is None:\n",
        "                break\n",
        "\n",
        "            if \"Carlsen\" not in game.headers.get(\"White\", \"\") and \"Carlsen\" not in game.headers.get(\"Black\", \"\"):\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "            magnus_color = \"white\" if \"Carlsen\" in game.headers.get(\"White\", \"\") else \"black\"\n",
        "            board = game.board()\n",
        "\n",
        "            for idx, move in enumerate(game.mainline_moves()):\n",
        "                if (magnus_color == \"white\" and idx % 2 == 0) or (magnus_color == \"black\" and idx % 2 == 1):\n",
        "                    fen = board.fen()\n",
        "                    true_move = move.uci()\n",
        "\n",
        "                    inputs = tokenize_fen(fen, tokenizer)\n",
        "                    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        logits = model(**inputs)[\"logits\"]\n",
        "                        sorted_indices = torch.argsort(logits, dim=-1, descending=True)[0]\n",
        "\n",
        "                        predicted_move = None\n",
        "                        temp_board = chess.Board(fen)\n",
        "                        for idxx in sorted_indices:\n",
        "                            from_sq = (idxx // 64).item()\n",
        "                            to_sq = (idxx % 64).item()\n",
        "                            candidate_move = chess.Move(from_sq, to_sq)\n",
        "                            if candidate_move in temp_board.legal_moves:\n",
        "                                predicted_move = candidate_move.uci()\n",
        "                                break\n",
        "\n",
        "                    total += 1\n",
        "                    if predicted_move == true_move:\n",
        "                        correct += 1\n",
        "\n",
        "                    # Update progress bar description with live accuracy\n",
        "                    if total % 10 == 0:\n",
        "                        acc = correct / total\n",
        "                        pbar.set_postfix_str(f\"Acc: {acc:.4f} ({correct}/{total})\")\n",
        "\n",
        "                board.push(move)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "# Final output\n",
        "accuracy = correct / total if total > 0 else 0\n",
        "print(f\"\\nFinal Accuracy: {accuracy:.4f} ({correct}/{total})\")\n"
      ],
      "metadata": {
        "id": "AmBJot3rofFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, upload_folder\n",
        "import os\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "repo_id = \"strumber/magnusTransformer\"\n",
        "local_folder = \"./fine_tuned_chessgpt2\"\n",
        "\n",
        "api = HfApi()\n",
        "api.create_repo(repo_id=repo_id, token=hf_token, exist_ok=True)\n",
        "\n",
        "upload_folder(\n",
        "    folder_path=local_folder,\n",
        "    repo_id=repo_id,\n",
        "    token=hf_token,\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "\n",
        "print(\"Model & tokenizer pushed to Hugging Face Hub!\")"
      ],
      "metadata": {
        "id": "mGr7CGMVrgQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}